#intial primer search from MRI primers-formatted accordingly-using exclusive database
python3 ~/HMAS-QC-Pipeline/extract_amplicon_from_primersearch_output_UnO.py -s /scicomp/groups/OID/NCEZID/DFWED/EDLB/projects/metagenomics/binning/insilico/genomefolder/fasta -p /scicomp/home-pure/uel3/UNDIs_MRI/primerFiles/allSal_primers.txt
#need to select the metasheet.csv files that have content, anything below 21c are empty
find . -type f -name "*meta*" -size +21c | while read -r file; do tail -n +2 "$file"; done > concatenated_file.txt
python3 primer_dict_redo.py #this prints all primers that generate amplicons in any/only salmonella located in /scicomp/home-pure/uel3/UNDIs_MRI/primersearch_JSB_allSAL
import sys

# List of valid prefixes for fasta names
valid_prefixes = ["1143560907", "749310542", "749314519", "1004367656", "1133548812", "983532915", "1151114342", "58156"]  # These are salmonella fasta file names

# Initialize an empty dictionary to store the data
primer_fasta_dict_with_desired_prefixes = {}

# Get the input file path from the command line arguments
if len(sys.argv) != 2:
    print("Usage: python3 primer_dict_redo.py concatenated_file.txt")
    sys.exit(1)

input_file_path = sys.argv[1]

# Read the file line by line
with open(input_file_path, 'r') as file:
    for line in file:
        # Split the line into columns using comma as the separator
        columns = line.strip().split(',')  # Adjust the separator if needed

        # Ensure the line has at least 3 columns
        if len(columns) >= 3:
            primer_name = columns[1]  # Primer name is the second column
            fasta_name = columns[2]  # Fasta name is the third column

            # Check if the primer_name already exists in the dictionary
            if primer_name in primer_fasta_dict_with_desired_prefixes:
                primer_fasta_dict_with_desired_prefixes[primer_name].append(fasta_name)
            else:
                primer_fasta_dict_with_desired_prefixes[primer_name] = [fasta_name]

# Filter primer names with at least one desired prefix in their associated fasta names
filtered_dict = {}
for primer, fasta_list in primer_fasta_dict_with_desired_prefixes.items():
    if all(fasta.startswith(tuple(valid_prefixes)) for fasta in fasta_list):
        filtered_dict[primer] = fasta_list

# Write the dictionaries to the output file
with open('primer_fasta_with_desired_prefixes.txt', 'w') as file:
    for primer, fasta_list in filtered_dict.items():
        file.write(f"{primer}: {fasta_list}\n")

python3 new_extract_primer_names.py #this will take the input from primer_dict_redo.py and tell you which primers from that dictionary have amplicons in all desired fasta names
import sys

def find_keys_with_values(dictionaries, target_values):
    matching_keys = []

    for dictionary in dictionaries:
        for key, values in dictionary.items():
            if all(value in values for value in target_values):
                matching_keys.append(key)

    return matching_keys

def main():
    if len(sys.argv) != 2:
        print("Usage: python script.py input_file.txt")
        return

    input_file = sys.argv[1]
    output_file = "primers_in_all_rep_species.txt"  # Set the output file name here

    with open(input_file, "r") as file:
        lines = file.readlines()

    dictionaries = []
    for line in lines:
        key, values_str = line.strip().split(":")
        values = [value.strip("' ") for value in values_str.strip(" []").split(",")]
        dictionaries.append({key: values})

    target_values = {'1143560907', '749310542', '749314519', '1004367656', '1133548812', '983532915', '1151114342', '58156'}  # Note: Using strings as values

    matching_keys = find_keys_with_values(dictionaries, target_values)

    with open(output_file, "w") as outfile:
        for key in matching_keys:
            outfile.write(key + "\n")

if __name__ == "__main__":
    main()


grep -f primers_in_all_rep_species.txt allSal_primers.txt > secondary_test_primers.txt

#secondary primers search using inclusive database
python3  ~/HMAS-QC-Pipeline/extract_amplicon_from_primersearch_output_UnO.py -s /scicomp/home-pure/uel3/UNDIs_MRI/ecoli_refseq_genomes/unzipped -p ~/secondary_test_primers.txt

find . -type f -name "*meta*" -size +21c | while read -r file; do tail -n +2 "$file"; done > concatenated_file_secondary.txt
python3 primer_dictionaries.py concatenated_file_secondary.txt #primer dictionaries creates a dictionary file to pull primer stats from
import sys

def create_dictionaries(input_file):
    fasta_dict = {}

    with open(input_file, "r") as file:
        for line in file:
            seqid, primer_name, fasta_name = line.strip().split(",")
            if fasta_name not in fasta_dict:
                fasta_dict[fasta_name] = []
            fasta_dict[fasta_name].append(primer_name)

    return fasta_dict

def main():
    if len(sys.argv) != 2:
        print("Usage: python script.py input_file.txt")
        return

    input_file = sys.argv[1]
    fasta_dict = create_dictionaries(input_file)

    with open("fasta_primer_dictionary.txt", "w") as output_file:
        for fasta_name, primer_names in fasta_dict.items():
            output_file.write(f"Fasta Name: {fasta_name}\n")
            output_file.write(f"  Primer Names: {', '.join(primer_names)}\n")

if __name__ == "__main__":
    main()

python3 primer_coverage.py fasta_primer_dictionary.txt #this will count the frequency of primers across representative databases 
import sys
from collections import defaultdict, Counter

def normalize_primer_name(primer_name):
    return primer_name.strip().replace("Primer Names: ", "")

def count_primer_frequencies(input_file):
    primer_frequencies = Counter()
    primer_occurrences = defaultdict(set)

    with open(input_file, "r") as file:
        lines = file.readlines()
        fasta_name = None

        for line in lines:
            if line.startswith("Fasta Name: "):
                fasta_name = line.strip().replace("Fasta Name: ", "")
            elif fasta_name and line.startswith("  Primer Names: "):
                primer_names = line.strip().replace("  Primer Names: ", "").split(", ")
                primer_names = [normalize_primer_name(primer_name) for primer_name in primer_names]
                primer_frequencies.update(primer_names)
                for primer_name in primer_names:
                    primer_occurrences[primer_name].add(fasta_name)

    return primer_frequencies, primer_occurrences

def main():
    if len(sys.argv) != 2:
        print("Usage: python3 primer_coverage.py input_file.txt")
        return

    input_file = sys.argv[1]
    primer_frequencies, primer_occurrences = count_primer_frequencies(input_file)
    total_fasta_names = len(set(fasta_name for fasta_names in primer_occurrences.values() for fasta_name in fasta_names))

    for primer_name, frequency in primer_frequencies.items():
        occurrence_count = len(primer_occurrences[primer_name])
        coverage_percentage = (occurrence_count / total_fasta_names) * 100
        print(f"Primer Name: {primer_name}, Frequency: {frequency}, Coverage: {coverage_percentage:.2f}%")

if __name__ == "__main__":
    main()
